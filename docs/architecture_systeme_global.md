# Architecture Syst√®me Global - Lakehouse Accidents US

## üéØ Objectifs Architecturaux

**Analyses M√©tier Cibl√©es :**
- **Analyse Temporelle** : Patterns d'accidents par heure/jour/saison/conditions m√©t√©o
- **Analyse G√©ographique** : Cartographie des zones √† risque par type d'infrastructure

**Contraintes Techniques :**
- Cluster Hadoop on-premise (HDFS, Hive, Yarn)
- 32GB RAM total, 8GB max Spark
- Dataset 7.7M records, 47 colonnes, 3GB
- Ingestion mixte : streaming + batch + g√©n√©rateur de donn√©es
- PySpark uniquement, documentation fran√ßaise

## üèóÔ∏è Architecture Syst√®me Global

```mermaid
graph TB
    subgraph "SOURCES DE DONN√âES"
        CSV[US_Accidents_March23.csv<br/>7.7M records, 3GB]
        GEN[G√©n√©rateur Temps R√©el<br/>Simulation nouvelles donn√©es]
        HIST[Donn√©es Historiques<br/>Retraitements batch]
    end

    subgraph "COUCHE BRONZE - HDFS"
        HDFS_RAW[HDFS Raw Data<br/>Parquet partitionn√©<br/>date/state]
        HDFS_STREAM[HDFS Streaming<br/>Micro-batches<br/>Delta format]
    end

    subgraph "APPLICATIONS SPARK"
        FEEDER[FEEDER<br/>Ingestion & Validation]
        PREPROCESSOR[PREPROCESSOR<br/>Nettoyage & Features]
        DATAMART[DATAMART<br/>Agr√©gations Business]
        MLTRAINING[MLTRAINING<br/>Pipeline ML]
    end

    subgraph "COUCHE SILVER - HIVE"
        HIVE_CLEAN[accidents_clean<br/>Donn√©es nettoy√©es]
        HIVE_WEATHER[weather_aggregated<br/>Agr√©gations m√©t√©o]
        HIVE_INFRA[infrastructure_features<br/>Features infrastructure]
        HIVE_TEMPORAL[temporal_patterns<br/>Patterns temporels]
        HIVE_GEO[geographic_hotspots<br/>Zones √† risque]
    end

    subgraph "COUCHE GOLD - MYSQL"
        MYSQL_KPI[KPIs Dashboard<br/>M√©triques temps r√©el]
        MYSQL_HOTSPOTS[Hotspots G√©ographiques<br/>Zones critiques]
        MYSQL_TEMPORAL[Patterns Temporels<br/>Analyses saisonni√®res]
        MYSQL_PREDICTIONS[Pr√©dictions ML<br/>Scores de risque]
    end

    subgraph "API & INTERFACES"
        API[FastAPI REST<br/>Swagger fran√ßais]
        SWAGGER[Documentation API<br/>Endpoints m√©tier]
    end

    subgraph "MONITORING & CONFIG"
        YARN[Yarn Resource Manager<br/>32GB RAM, 8GB Spark]
        LOG[Logging Structur√©<br/>Monitoring pipeline]
        ENV[Configuration .env<br/>Variables externalis√©es]
    end

    CSV --> FEEDER
    GEN --> FEEDER
    HIST --> FEEDER
    
    FEEDER --> HDFS_RAW
    FEEDER --> HDFS_STREAM
    
    HDFS_RAW --> PREPROCESSOR
    HDFS_STREAM --> PREPROCESSOR
    
    PREPROCESSOR --> HIVE_CLEAN
    PREPROCESSOR --> HIVE_WEATHER
    PREPROCESSOR --> HIVE_INFRA
    PREPROCESSOR --> HIVE_TEMPORAL
    PREPROCESSOR --> HIVE_GEO
    
    HIVE_CLEAN --> DATAMART
    HIVE_WEATHER --> DATAMART
    HIVE_INFRA --> DATAMART
    HIVE_TEMPORAL --> DATAMART
    HIVE_GEO --> DATAMART
    
    DATAMART --> MYSQL_KPI
    DATAMART --> MYSQL_HOTSPOTS
    DATAMART --> MYSQL_TEMPORAL
    
    HIVE_CLEAN --> MLTRAINING
    MLTRAINING --> MYSQL_PREDICTIONS
    
    MYSQL_KPI --> API
    MYSQL_HOTSPOTS --> API
    MYSQL_TEMPORAL --> API
    MYSQL_PREDICTIONS --> API
    
    API --> SWAGGER
    
    YARN -.-> FEEDER
    YARN -.-> PREPROCESSOR
    YARN -.-> DATAMART
    YARN -.-> MLTRAINING
    
    LOG -.-> FEEDER
    LOG -.-> PREPROCESSOR
    LOG -.-> DATAMART
    LOG -.-> MLTRAINING
    
    ENV -.-> API
    ENV -.-> FEEDER
    ENV -.-> PREPROCESSOR
    ENV -.-> DATAMART
    ENV -.-> MLTRAINING
```

## üìä Flux de Donn√©es D√©taill√©

### Couche Bronze (HDFS)
- **Format** : Parquet avec compression Snappy
- **Partitioning** : Par date (YYYY/MM/DD) et √©tat (state)
- **Validation** : Sch√©ma strict des 47 colonnes
- **R√©tention** : 2 ans de donn√©es historiques

### Couche Silver (Hive)
- **Tables principales** :
  - `accidents_clean` : Donn√©es nettoy√©es et enrichies
  - `weather_aggregated` : Agr√©gations m√©t√©orologiques
  - `infrastructure_features` : Features d'infrastructure
  - `temporal_patterns` : Patterns temporels
  - `geographic_hotspots` : Zones √† risque g√©ographiques

### Couche Gold (MySQL)
- **Tables optimis√©es** pour les requ√™tes API
- **Indexation** sur les colonnes de filtrage fr√©quentes
- **Agr√©gations pr√©-calcul√©es** pour les KPIs
- **Mise √† jour** quotidienne via les applications Spark

## üîÑ Applications Spark

### 1. FEEDER
- **Responsabilit√©** : Ingestion et validation des donn√©es
- **Fr√©quence** : Quotidienne + streaming temps r√©el
- **Optimisations** : Partitioning intelligent, validation sch√©ma

### 2. PREPROCESSOR
- **Responsabilit√©** : Nettoyage et feature engineering
- **Fr√©quence** : Apr√®s chaque ingestion
- **Optimisations** : Cache des DataFrames, broadcast des tables de r√©f√©rence

### 3. DATAMART
- **Responsabilit√©** : Agr√©gations business et export MySQL
- **Fr√©quence** : Quotidienne
- **Optimisations** : Bucketing pour jointures, coalesce pour optimiser les fichiers

### 4. MLTRAINING
- **Responsabilit√©** : Entra√Ænement mod√®les ML et pr√©dictions
- **Fr√©quence** : Hebdomadaire pour r√©entra√Ænement
- **Optimisations** : Cache du dataset d'entra√Ænement, repartition √©quilibr√©e

## üéØ Justifications Architecturales

### Choix du Lakehouse
- **Flexibilit√©** : Support des donn√©es structur√©es et semi-structur√©es
- **Performance** : Optimisations Spark pour les gros volumes
- **√âvolutivit√©** : Architecture modulaire extensible
- **Co√ªt** : Utilisation optimale des ressources Hadoop existantes

### Strat√©gie Multi-Couches
- **Bronze** : Donn√©es brutes pour audit et retraitement
- **Silver** : Donn√©es nettoy√©es pour analyses avanc√©es
- **Gold** : Donn√©es agr√©g√©es pour performance API

### Choix Technologiques
- **PySpark** : √âcosyst√®me Python riche pour ML et analyse
- **Hive** : Int√©gration native avec Hadoop, m√©tadonn√©es centralis√©es
- **MySQL** : Performance pour requ√™tes OLTP de l'API
- **FastAPI** : Performance et documentation automatique