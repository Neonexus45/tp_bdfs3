#!/bin/bash

echo "üöÄ D√©marrage du cluster lakehouse Docker (MySQL externe)..."

# Chargement des variables d'environnement
if [ -f .env ]; then
    export $(cat .env | grep -v '^#' | xargs)
else
    echo "‚ùå Fichier .env non trouv√©!"
    exit 1
fi

# V√©rification de la connectivit√© MySQL
echo "üîç V√©rification connectivit√© MySQL externe..."
if ! mysql -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u ${MYSQL_USER} -p${MYSQL_PASSWORD} -e "SELECT 1;" > /dev/null 2>&1; then
    echo "‚ùå Impossible de se connecter au serveur MySQL externe"
    echo "V√©rifiez les variables MYSQL_* dans le fichier .env"
    echo "Host: ${MYSQL_HOST}:${MYSQL_PORT}"
    echo "User: ${MYSQL_USER}"
    exit 1
fi

echo "‚úÖ Connexion MySQL r√©ussie!"

# Cr√©ation des bases de donn√©es si n√©cessaire
echo "üìä Cr√©ation des bases de donn√©es MySQL..."
mysql -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u ${MYSQL_USER} -p${MYSQL_PASSWORD} < scripts/setup-mysql-tables.sql

if [ $? -eq 0 ]; then
    echo "‚úÖ Bases de donn√©es cr√©√©es avec succ√®s!"
else
    echo "‚ùå Erreur lors de la cr√©ation des bases de donn√©es"
    exit 1
fi

# Nettoyage des conteneurs existants
echo "üßπ Nettoyage des conteneurs existants..."
docker-compose down -v 2>/dev/null

# Construction des images personnalis√©es
echo "üî® Construction de l'image MLflow..."
docker-compose build mlflow

# D√©marrage des services Docker
echo "üê≥ D√©marrage des conteneurs Docker..."
docker-compose up -d

# Attendre que les services soient pr√™ts
echo "‚è≥ Attente initialisation des services..."
echo "   - NameNode..."
sleep 30

# V√©rification que NameNode est pr√™t
while ! docker exec namenode hdfs dfsadmin -report > /dev/null 2>&1; do
    echo "   - NameNode pas encore pr√™t, attente 10 secondes..."
    sleep 10
done

echo "‚úÖ NameNode pr√™t!"

# Initialisation HDFS
echo "üìÅ Initialisation HDFS..."
docker exec namenode hdfs dfsadmin -safemode leave 2>/dev/null
docker exec namenode hdfs dfs -mkdir -p /user/hive/warehouse
docker exec namenode hdfs dfs -chmod 777 /user/hive/warehouse

# Cr√©ation r√©pertoires projet
echo "üìÇ Cr√©ation des r√©pertoires de donn√©es..."
docker exec namenode hdfs dfs -mkdir -p /data/bronze
docker exec namenode hdfs dfs -mkdir -p /data/silver  
docker exec namenode hdfs dfs -mkdir -p /data/gold
docker exec namenode hdfs dfs -mkdir -p /data/raw
docker exec namenode hdfs dfs -mkdir -p /data/processed

# Permissions
docker exec namenode hdfs dfs -chmod -R 777 /data
docker exec namenode hdfs dfs -chmod -R 777 /user

echo "‚úÖ HDFS initialis√© avec succ√®s!"

# Attendre que Spark soit pr√™t
echo "‚è≥ Attente de Spark Master..."
sleep 15

# Attendre que Hive soit pr√™t
echo "‚è≥ Attente de Hive Metastore..."
sleep 20

# Attendre que MLflow soit pr√™t
echo "‚è≥ Attente de MLflow..."
sleep 10

# V√©rification des services
echo "üîç V√©rification des services..."

# Test HDFS
if docker exec namenode hdfs dfs -ls / > /dev/null 2>&1; then
    echo "‚úÖ HDFS op√©rationnel"
else
    echo "‚ö†Ô∏è  HDFS non accessible"
fi

# Test Spark
if curl -s http://localhost:8080 > /dev/null; then
    echo "‚úÖ Spark Master op√©rationnel"
else
    echo "‚ö†Ô∏è  Spark Master non accessible"
fi

# Test Hive
if docker exec hive-metastore /opt/hive/bin/schematool -dbType mysql -info > /dev/null 2>&1; then
    echo "‚úÖ Hive Metastore op√©rationnel"
else
    echo "‚ö†Ô∏è  Hive Metastore non accessible"
fi

# Test MLflow
if curl -s http://localhost:5000 > /dev/null; then
    echo "‚úÖ MLflow op√©rationnel"
else
    echo "‚ö†Ô∏è  MLflow non accessible"
fi

echo ""
echo "üéâ Cluster lakehouse d√©marr√© avec MySQL externe!"
echo ""
echo "üåê Interfaces Web disponibles:"
echo "   - HDFS NameNode:        http://localhost:9870"
echo "   - Yarn ResourceManager: http://localhost:8088"
echo "   - Spark Master:         http://localhost:8080"
echo "   - Spark Worker:         http://localhost:8081"
echo "   - Hive Server2:         http://localhost:10002"
echo "   - MLflow:               http://localhost:5000"
echo ""
echo "üîó Connexions services:"
echo "   - HDFS:                 hdfs://localhost:9000"
echo "   - Spark Master:         spark://localhost:7077"
echo "   - Hive Metastore:       thrift://localhost:9083"
echo "   - HiveServer2:          jdbc:hive2://localhost:10000"
echo ""
echo "üìä Bases de donn√©es MySQL cr√©√©es:"
echo "   - accidents_db:         Tables Gold Layer"
echo "   - hive_metastore:       M√©tadonn√©es Hive"
echo "   - mlflow_db:            Tracking MLflow"
echo ""
echo "üìÅ R√©pertoires HDFS cr√©√©s:"
echo "   - /data/bronze:         Donn√©es brutes"
echo "   - /data/silver:         Donn√©es nettoy√©es"
echo "   - /data/gold:           Donn√©es agr√©g√©es"
echo "   - /user/hive/warehouse: Entrep√¥t Hive"
echo ""
echo "üöÄ Le cluster est pr√™t pour le traitement des donn√©es!"