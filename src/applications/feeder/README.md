# FEEDER Application - Ingestion des Donn√©es US-Accidents

## Vue d'ensemble

L'application **FEEDER** est responsable de l'ingestion quotidienne des donn√©es US-Accidents dans l'architecture lakehouse. Elle impl√©mente un pipeline complet d'ingestion avec validation, contr√¥le qualit√© et optimisations Spark.

## Fonctionnalit√©s Principales

### üîç Lecture CSV Optimis√©e
- **Sch√©ma strict** des 47 colonnes exactes du dataset US-Accidents
- **Gestion des types** (string, double, boolean, timestamp)
- **Optimisations lecture** (multiline, encoding, delimiter)
- **Cache intelligent** des DataFrames

### ‚úÖ Validation de Sch√©ma
- **Sch√©ma US-Accidents pr√©-d√©fini** avec types exacts
- **Validation structure** (nombre colonnes, noms, types)
- **D√©tection colonnes** manquantes/suppl√©mentaires
- **Rapports de validation** d√©taill√©s

### üîç Contr√¥le Qualit√©
- **Validation coordonn√©es GPS** (latitude/longitude valides)
- **V√©rification codes d'√©tat** am√©ricains (State column)
- **D√©tection outliers** (Distance, Temperature, etc.)
- **Calcul m√©triques qualit√©** (% nulls, doublons, etc.)

### üìä Partitioning Intelligent
- **Partitioning par date** d'ingestion (YYYY/MM/DD)
- **Sous-partitioning par √©tat** (State column)
- **Optimisation nombre de partitions** (√©viter small files)
- **Coalescing intelligent** avant √©criture

### ‚ö° Optimisations Spark
- **Partitioning**: 200 partitions optimales pour 3GB
- **Compression**: Snappy pour balance compression/vitesse
- **Cache**: DataFrames r√©utilis√©s en m√©moire
- **Coalesce**: √âviter les petits fichiers (<128MB)

## Architecture des Composants

```
src/applications/feeder/
‚îú‚îÄ‚îÄ __init__.py                 # Exports et m√©tadonn√©es
‚îú‚îÄ‚îÄ feeder_app.py              # Application principale
‚îú‚îÄ‚îÄ data_ingestion.py          # Logique ingestion
‚îú‚îÄ‚îÄ schema_validator.py        # Validation sch√©ma
‚îú‚îÄ‚îÄ quality_checker.py         # Contr√¥le qualit√©
‚îú‚îÄ‚îÄ partitioning_strategy.py   # Strat√©gie partitioning
‚îú‚îÄ‚îÄ test_feeder.py            # Tests unitaires
‚îî‚îÄ‚îÄ README.md                 # Documentation
```

## Classes Principales

### 1. FeederApp
**Application principale** avec orchestration du pipeline d'ingestion.

```python
from src.applications.feeder import FeederApp

feeder = FeederApp()
result = feeder.run()
```

**Fonctionnalit√©s:**
- H√©rite de la classe de base SparkApplication
- Orchestration du pipeline d'ingestion
- Gestion des erreurs et retry automatique (3 tentatives)
- M√©triques de performance et logging structur√©

### 2. DataIngestion
**Lecture CSV** avec sch√©ma d√©fini et optimisations.

```python
from src.applications.feeder import DataIngestion

ingestion = DataIngestion()
df = ingestion.read_csv_data("path/to/file.csv")
```

**Fonctionnalit√©s:**
- Lecture CSV avec sch√©ma strict (47 colonnes)
- Gestion des types de donn√©es
- Cache intelligent bas√© sur la taille
- Validation post-lecture

### 3. SchemaValidator
**Validation stricte** du sch√©ma US-Accidents.

```python
from src.applications.feeder import SchemaValidator

validator = SchemaValidator()
result = validator.validate_dataframe_schema(df)
```

**Fonctionnalit√©s:**
- Sch√©ma pr√©-d√©fini avec types exacts
- D√©tection colonnes manquantes/suppl√©mentaires
- Rapports de validation d√©taill√©s
- Mode strict configurable

### 4. QualityChecker
**Contr√¥le qualit√©** et nettoyage des donn√©es.

```python
from src.applications.feeder import QualityChecker

checker = QualityChecker()
quality_report = checker.check_data_quality(df)
cleaned_df = checker.clean_corrupted_data(df)
```

**Fonctionnalit√©s:**
- Validation coordonn√©es GPS US
- V√©rification codes d'√©tat am√©ricains
- D√©tection outliers statistiques
- Score de qualit√© automatique

### 5. PartitioningStrategy
**Strat√©gie de partitioning** intelligent.

```python
from src.applications.feeder import PartitioningStrategy

strategy = PartitioningStrategy()
partitioned_df = strategy.apply_partitioning(df, 'auto')
```

**Fonctionnalit√©s:**
- Partitioning par date et √©tat
- Optimisation automatique du nombre de partitions
- Coalescing intelligent
- Strat√©gies configurables

## Configuration

### Variables d'Environnement

```bash
# Source des donn√©es
DATA_SOURCE_PATH=data/raw/US_Accidents_March23.csv
DATA_EXPECTED_COLUMNS=47
DATA_EXPECTED_ROWS=7700000

# Partitioning
PARTITION_COLUMNS=["date", "state"]
COMPRESSION_CODEC=snappy
PARQUET_COMPRESSION=snappy

# Chemins HDFS
HDFS_BRONZE_PATH=/lakehouse/accidents/bronze
HDFS_NAMENODE=hdfs://localhost:9000

# Spark
SPARK_SQL_SHUFFLE_PARTITIONS=200
SPARK_SQL_ADAPTIVE_ENABLED=true
```

### Configuration Spark Optimis√©e

L'application utilise une configuration Spark sp√©cialement optimis√©e pour l'ingestion:

```python
spark_config = {
    'spark.sql.adaptive.coalescePartitions.enabled': 'true',
    'spark.sql.files.maxPartitionBytes': '134217728',  # 128MB
    'spark.sql.adaptive.advisoryPartitionSizeInBytes': '67108864',  # 64MB
    'spark.sql.files.openCostInBytes': '4194304',  # 4MB
}
```

## M√©triques et Logging

### M√©triques Collect√©es
- **Nombre d'enregistrements** lus/√©crits
- **Temps d'ex√©cution** par √©tape
- **Taille fichiers** source/destination
- **M√©triques qualit√©** (% erreurs, nulls, doublons)
- **Utilisation ressources** (CPU, m√©moire, I/O)
- **Nombre de partitions** cr√©√©es

### Format de Logging
Tous les logs sont structur√©s en JSON:

```json
{
  "timestamp": "2023-12-19T21:15:32Z",
  "level": "INFO",
  "application": "feeder",
  "operation": "csv_data_ingestion",
  "duration_seconds": 45.2,
  "records_read": 7700000,
  "file_size_mb": 3072.5,
  "quality_score": 87.3
}
```

## Gestion d'Erreurs

### Retry Automatique
- **3 tentatives maximum** avec backoff exponentiel
- **Isolation des enregistrements** corrompus
- **Logging d√©taill√©** des erreurs avec contexte
- **Fallback vers mode d√©grad√©** si n√©cessaire

### Types d'Erreurs G√©r√©es
- `FileProcessingError`: Probl√®mes de lecture fichier
- `SchemaValidationError`: Sch√©ma non conforme
- `DataQualityError`: Qualit√© insuffisante
- `SparkJobError`: Erreurs d'ex√©cution Spark

## Tests

### Ex√©cution des Tests

```bash
# Tests complets
python src/applications/feeder/test_feeder.py

# Tests individuels
python -c "from src.applications.feeder.test_feeder import FeederTester; t = FeederTester(); print(t.test_data_ingestion())"
```

### Types de Tests
- **Test DataIngestion**: Lecture CSV et m√©triques
- **Test SchemaValidator**: Validation sch√©ma
- **Test QualityChecker**: Contr√¥le qualit√©
- **Test PartitioningStrategy**: Strat√©gies de partitioning
- **Test FeederApp**: Application compl√®te

## Usage

### Ex√©cution Simple

```python
from src.applications.feeder import FeederApp

# Cr√©ation et ex√©cution
feeder = FeederApp()
result = feeder.run()

if result['status'] == 'success':
    print(f"‚úÖ Ingestion r√©ussie: {result['metrics']['records_written']} enregistrements")
else:
    print(f"‚ùå √âchec: {result['message']}")
```

### Ex√©cution en Ligne de Commande

```bash
# Ex√©cution directe
python src/applications/feeder/feeder_app.py

# Avec configuration personnalis√©e
DATA_SOURCE_PATH=/custom/path/data.csv python src/applications/feeder/feeder_app.py
```

### Utilisation des Composants Individuels

```python
from src.applications.feeder import DataIngestion, SchemaValidator, QualityChecker

# Pipeline personnalis√©
ingestion = DataIngestion()
validator = SchemaValidator()
checker = QualityChecker()

# Lecture
df = ingestion.read_csv_data("data.csv")

# Validation
schema_result = validator.validate_dataframe_schema(df)
if not schema_result['is_valid']:
    raise Exception("Sch√©ma invalide")

# Contr√¥le qualit√©
quality_result = checker.check_data_quality(df)
if quality_result['overall_quality_score'] < 70:
    df = checker.clean_corrupted_data(df)
```

## Performance

### Benchmarks Typiques
- **Fichier 3GB (7.7M enregistrements)**: ~5-8 minutes
- **D√©bit lecture**: ~400-600 MB/min
- **Partitions cr√©√©es**: ~200-400 selon les donn√©es
- **Compression Snappy**: ~60-70% r√©duction taille

### Optimisations Recommand√©es
- **M√©moire Spark**: Minimum 4GB driver, 8GB executors
- **Partitions**: 200 partitions pour 3GB de donn√©es
- **Cache**: Activ√© pour DataFrames < 1GB
- **Coalescing**: Fichiers finaux ~128MB chacun

## Monitoring

### M√©triques Cl√©s √† Surveiller
- **Temps d'ex√©cution total** (SLA: < 10 minutes)
- **Score de qualit√©** (Seuil: > 80%)
- **Taux d'erreur** (Seuil: < 5%)
- **Utilisation m√©moire** (Seuil: < 80%)

### Alertes Configur√©es
- √âchec d'ingestion apr√®s 3 tentatives
- Score de qualit√© < 70%
- Temps d'ex√©cution > 15 minutes
- Utilisation m√©moire > 90%

## D√©pannage

### Probl√®mes Courants

**1. Erreur de sch√©ma**
```
SchemaValidationError: Missing required columns: ['ID', 'State']
```
‚Üí V√©rifier le format du fichier source et les 47 colonnes

**2. Qualit√© insuffisante**
```
DataQualityError: Quality score 45.2 below threshold 70.0
```
‚Üí Examiner les m√©triques de qualit√© et nettoyer les donn√©es

**3. Erreur de partitioning**
```
SparkJobError: Partitioning failed: Invalid state codes
```
‚Üí V√©rifier les codes d'√©tat am√©ricains dans les donn√©es

### Logs de Debug

```bash
# Activation du debug
LOG_FEEDER_LEVEL=DEBUG python src/applications/feeder/feeder_app.py

# Logs d√©taill√©s
tail -f /var/log/lakehouse-accidents/feeder.log
```

## √âvolutions Futures

### Am√©liorations Pr√©vues
- **Streaming**: Support ingestion temps r√©el
- **Delta Lake**: Migration vers format Delta
- **Auto-scaling**: Ajustement automatique des ressources
- **ML Quality**: D√©tection anomalies par ML

### Int√©grations Planifi√©es
- **Apache Airflow**: Orchestration workflow
- **Prometheus**: M√©triques avanc√©es
- **Grafana**: Dashboards monitoring
- **Apache Atlas**: Gouvernance donn√©es