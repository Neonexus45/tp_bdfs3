# Application MLTRAINING

Application d'entra√Ænement de mod√®les ML pour la classification de s√©v√©rit√© des accidents de la route aux √âtats-Unis.

## Vue d'ensemble

L'application MLTRAINING constitue la couche ML de l'architecture Medallion, transformant les donn√©es enrichies de la couche Silver en mod√®les pr√©dictifs performants pour classifier la s√©v√©rit√© des accidents (1-4).

### Architecture Medallion - Couche ML

```
Bronze (FEEDER) ‚Üí Silver (PREPROCESSOR) ‚Üí Gold (DATAMART) ‚Üí ML (MLTRAINING)
     ‚Üì                    ‚Üì                     ‚Üì              ‚Üì
  HDFS Parquet      ‚Üí  Hive ORC         ‚Üí   MySQL        ‚Üí  MLflow
  Donn√©es brutes    ‚Üí  Features enrichies ‚Üí Analytics    ‚Üí  Mod√®les ML
```

## Fonctionnalit√©s principales

### üîß Pr√©paration des Features ML
- **Source** : Couche Silver (Hive table `accidents_clean`)
- **Features** : 47 colonnes US-Accidents + features enrichies (temporelles, m√©t√©o, g√©ographiques, infrastructure)
- **Preprocessing** : Scaling, encoding, feature selection, gestion outliers
- **Pipeline** : Reproductible et versionn√©

### ü§ñ Entra√Ænement Multi-Mod√®les
- **RandomForestClassifier** : Robuste et interpr√©table
- **GradientBoostingClassifier** : Performance √©lev√©e
- **LogisticRegression** : Baseline rapide
- **DecisionTreeClassifier** : Natif Spark

### üìä √âvaluation Compl√®te
- **M√©triques globales** : Accuracy, F1-score macro/micro, AUC
- **M√©triques par classe** : Precision, Recall, F1 pour chaque s√©v√©rit√©
- **Confusion Matrix** : Analyse d√©taill√©e des erreurs
- **Feature Importance** : Ranking des variables pr√©dictives

### ‚öôÔ∏è Optimisation Hyperparam√®tres
- **Grid Search** : Recherche exhaustive
- **Random Search** : Recherche al√©atoire efficace
- **Cross-validation** : Validation crois√©e k-fold
- **Optimisation** : Bas√©e sur F1-score macro

### üìà MLflow Integration
- **Tracking** : Exp√©riences, param√®tres, m√©triques
- **Model Registry** : Versioning et staging (Staging/Production)
- **Artifacts** : Mod√®les, visualisations, m√©tadonn√©es

### üîÆ Service de Pr√©diction
- **Chargement** : Mod√®les depuis MLflow Registry
- **Preprocessing** : Pipeline de transformation
- **Pr√©diction** : Classification avec scores de confiance
- **API** : Support batch et pr√©dictions unitaires

## Structure du projet

```
src/applications/mltraining/
‚îú‚îÄ‚îÄ __init__.py                    # Package initialization
‚îú‚îÄ‚îÄ mltraining_app.py             # Application principale
‚îú‚îÄ‚îÄ feature_processor.py          # Pr√©paration features ML
‚îú‚îÄ‚îÄ model_trainer.py              # Entra√Ænement mod√®les
‚îú‚îÄ‚îÄ model_evaluator.py            # √âvaluation et m√©triques
‚îú‚îÄ‚îÄ hyperparameter_tuner.py       # Tuning hyperparam√®tres
‚îú‚îÄ‚îÄ mlflow_manager.py             # Gestion MLflow
‚îú‚îÄ‚îÄ prediction_service.py         # Service de pr√©diction
‚îú‚îÄ‚îÄ test_mltraining.py            # Tests complets
‚îî‚îÄ‚îÄ README.md                     # Documentation
```

## Configuration

### Variables d'environnement

```bash
# MLflow
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_EXPERIMENT_NAME=accidents-severity-prediction
MLFLOW_ARTIFACT_ROOT=/mlflow/artifacts

# Hive
HIVE_METASTORE_URI=thrift://localhost:9083
HIVE_DATABASE=accidents_warehouse
HIVE_TABLE_ACCIDENTS_CLEAN=accidents_clean

# Spark ML
SPARK_DRIVER_MEMORY=4g
SPARK_EXECUTOR_MEMORY=2g
SPARK_EXECUTOR_CORES=2
```

### Configuration mod√®les

```python
# Param√®tres RandomForest
rf_params = {
    'numTrees': [50, 100, 200],
    'maxDepth': [10, 15, 20],
    'minInstancesPerNode': [1, 5, 10],
    'subsamplingRate': [0.8, 1.0]
}

# Param√®tres GradientBoosting
gb_params = {
    'maxIter': [50, 100, 150],
    'maxDepth': [5, 10, 15],
    'stepSize': [0.01, 0.1, 0.2],
    'subsamplingRate': [0.8, 1.0]
}
```

## Utilisation

### 1. Entra√Ænement complet

```python
from src.applications.mltraining.mltraining_app import MLTrainingApp

# Initialisation
ml_app = MLTrainingApp()
ml_app.initialize_components()

# Pipeline ML complet
result = ml_app.run_ml_pipeline()

print(f"Meilleur mod√®le: {result['model_info']['name']}")
print(f"Accuracy: {result['metrics']['accuracy']:.4f}")
print(f"F1-Score: {result['metrics']['f1_score_macro']:.4f}")
```

### 2. Entra√Ænement mod√®le sp√©cifique

```python
from src.applications.mltraining.model_trainer import ModelTrainer

trainer = ModelTrainer()

# Entra√Ænement Random Forest
rf_result = trainer.train_single_model(
    model_name='random_forest',
    train_df=train_data,
    validation_df=val_data,
    feature_columns=feature_list,
    target_column='Severity'
)

print(f"F1-Score: {rf_result['validation_metrics']['f1_score_macro']}")
```

### 3. Optimisation hyperparam√®tres

```python
from src.applications.mltraining.hyperparameter_tuner import HyperparameterTuner

tuner = HyperparameterTuner()

# Grid search
best_model, tuning_results = tuner.tune_model(
    model_name='random_forest',
    train_df=train_data,
    validation_df=val_data,
    feature_columns=feature_list,
    target_column='Severity',
    tuning_method='grid_search'
)

print(f"Meilleurs param√®tres: {tuning_results['best_params']}")
print(f"Score optimis√©: {tuning_results['best_score']}")
```

### 4. √âvaluation d√©taill√©e

```python
from src.applications.mltraining.model_evaluator import ModelEvaluator

evaluator = ModelEvaluator()

# √âvaluation compl√®te
evaluation = evaluator.evaluate_model(
    model=trained_model,
    test_df=test_data,
    feature_columns=feature_list,
    target_column='Severity',
    model_name='random_forest_tuned'
)

# M√©triques par classe
for class_name, metrics in evaluation['class_metrics'].items():
    print(f"{class_name}: Precision={metrics['precision']:.3f}, "
          f"Recall={metrics['recall']:.3f}, F1={metrics['f1_score']:.3f}")

# Matrice de confusion
confusion = evaluation['confusion_matrix']
print(f"Total √©chantillons: {confusion['total_samples']}")
```

### 5. Service de pr√©diction

```python
from src.applications.mltraining.prediction_service import PredictionService

# Initialisation du service
predictor = PredictionService()
predictor.load_model('accidents_severity_random_forest', stage='Production')

# Pr√©diction unitaire
accident_data = {
    'Distance_mi': 0.5,
    'Temperature_F': 65.0,
    'Humidity_percent': 60.0,
    'Start_Lat': 40.7128,
    'Start_Lng': -74.0060
}

prediction = predictor.predict_single(accident_data)
print(f"S√©v√©rit√© pr√©dite: {prediction['predicted_severity_name']}")
print(f"Confiance: {prediction['confidence_score']:.3f}")

# Pr√©diction batch
batch_predictions = predictor.predict(input_dataframe)
```

## Features utilis√©es

### 47 Colonnes originales US-Accidents

```python
# Variables num√©riques
numeric_features = [
    'Distance_mi', 'Temperature_F', 'Wind_Chill_F', 'Humidity_percent',
    'Pressure_in', 'Visibility_mi', 'Wind_Speed_mph', 'Precipitation_in',
    'Start_Lat', 'Start_Lng'
]

# Variables cat√©gorielles
categorical_features = [
    'Source', 'State', 'Weather_Condition', 'Sunrise_Sunset',
    'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight'
]

# Variables bool√©ennes infrastructure (13 colonnes)
boolean_features = [
    'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit',
    'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming',
    'Traffic_Signal', 'Turning_Loop'
]
```

### Features enrichies par PREPROCESSOR

```python
# Features temporelles
temporal_features = [
    'accident_hour', 'accident_day_of_week', 'accident_month',
    'accident_season', 'is_weekend', 'is_rush_hour'
]

# Features m√©t√©orologiques
weather_features = [
    'weather_category', 'weather_severity_score', 
    'visibility_category', 'temperature_category'
]

# Features g√©ographiques
geo_features = [
    'distance_to_city_center', 'urban_rural_classification',
    'state_region', 'population_density_category'
]

# Features infrastructure agr√©g√©es
infra_features = [
    'infrastructure_count', 'safety_equipment_score', 'traffic_control_type'
]
```

## M√©triques et √©valuation

### M√©triques globales

- **Accuracy** : Pourcentage de pr√©dictions correctes
- **F1-Score Macro** : Moyenne des F1 par classe (m√©trique principale)
- **F1-Score Micro** : F1 global pond√©r√©
- **AUC Macro** : Moyenne des AUC par classe

### M√©triques par classe de s√©v√©rit√©

| S√©v√©rit√© | Description | M√©triques |
|----------|-------------|-----------|
| 1 | Minor | Precision, Recall, F1-Score, Support |
| 2 | Moderate | Precision, Recall, F1-Score, Support |
| 3 | Serious | Precision, Recall, F1-Score, Support |
| 4 | Severe | Precision, Recall, F1-Score, Support |

### Analyses avanc√©es

- **Confusion Matrix** : Matrice d'erreurs d√©taill√©e
- **Feature Importance** : Ranking des variables les plus importantes
- **ROC/AUC** : Courbes ROC pour chaque classe
- **Calibration** : Qualit√© des probabilit√©s pr√©dites

## MLflow Integration

### Tracking des exp√©riences

```python
# Logging automatique
with mlflow.start_run():
    mlflow.log_params(model_params)
    mlflow.log_metrics(evaluation_metrics)
    mlflow.spark.log_model(model, "model")
    mlflow.log_artifacts("plots/")
```

### Model Registry

- **Staging** : Mod√®les en test
- **Production** : Mod√®les d√©ploy√©s
- **Archived** : Anciens mod√®les

### Artifacts sauvegard√©s

- Mod√®les Spark ML
- M√©tadonn√©es des features
- Matrices de confusion
- Graphiques de performance
- Configuration des hyperparam√®tres

## Optimisations Spark ML

### Configuration m√©moire

```python
spark_config = {
    'spark.driver.memory': '4g',
    'spark.executor.memory': '2g',
    'spark.executor.cores': '2',
    'spark.sql.adaptive.enabled': 'true',
    'spark.serializer': 'org.apache.spark.serializer.KryoSerializer'
}
```

### Pipeline optimis√©

- **Feature Caching** : Cache des features transform√©es
- **Broadcast Variables** : Tables de r√©f√©rence pour encoding
- **Partitioning** : Donn√©es √©quilibr√©es par partition
- **Vectorisation** : Assemblage efficace des features

## Tests

### Ex√©cution des tests

```bash
# Tests unitaires
python -m pytest src/applications/mltraining/test_mltraining.py -v

# Tests sp√©cifiques
python -m pytest src/applications/mltraining/test_mltraining.py::TestMLTrainingApp -v

# Tests avec couverture
python -m pytest src/applications/mltraining/test_mltraining.py --cov=src.applications.mltraining
```

### Types de tests

- **Tests unitaires** : Chaque composant individuellement
- **Tests d'int√©gration** : Pipeline ML complet
- **Tests de performance** : M√©triques et temps d'ex√©cution
- **Tests de validation** : Qualit√© des donn√©es et mod√®les

## Monitoring et logging

### M√©triques applicatives

```json
{
  "operation": "ml_training_pipeline",
  "duration_seconds": 1847.3,
  "models_trained": 4,
  "best_model": "random_forest",
  "best_f1_score": 0.8734,
  "features_processed": 67,
  "training_samples": 5390000,
  "validation_samples": 1155000,
  "test_samples": 1155000
}
```

### Logging structur√©

- **JSON** : Format structur√© pour analyse
- **Niveaux** : DEBUG, INFO, WARNING, ERROR, CRITICAL
- **Contexte** : M√©tadonn√©es enrichies (mod√®le, √©tape, m√©triques)
- **Rotation** : Gestion automatique des fichiers de log

## D√©ploiement

### Pr√©requis

- Apache Spark 3.4+
- MLflow 2.4+
- Hive Metastore
- MySQL 8.0+
- Python 3.8+

### Installation

```bash
# Installation des d√©pendances
pip install -r requirements.txt

# Configuration des variables d'environnement
cp .env.example .env
# √âditer .env avec vos configurations

# Initialisation de la base de donn√©es
python scripts/init_ml_tables.py
```

### Ex√©cution

```bash
# Entra√Ænement complet
python -m src.applications.mltraining.mltraining_app

# Avec configuration personnalis√©e
python -m src.applications.mltraining.mltraining_app --config custom_config.yaml
```

## Troubleshooting

### Probl√®mes courants

1. **Erreur MLflow** : V√©rifier `MLFLOW_TRACKING_URI`
2. **M√©moire Spark** : Augmenter `spark.driver.memory`
3. **Donn√©es manquantes** : V√©rifier table Hive `accidents_clean`
4. **Performance** : Optimiser partitioning et cache

### Logs utiles

```bash
# Logs application
tail -f /var/log/lakehouse-accidents/mltraining.log

# Logs Spark
tail -f $SPARK_HOME/logs/spark-*.log

# Logs MLflow
tail -f /var/log/mlflow/mlflow.log
```

## Contribution

### Standards de code

- **PEP 8** : Style Python
- **Type hints** : Annotations de type
- **Docstrings** : Documentation des fonctions
- **Tests** : Couverture > 80%

### Workflow

1. Fork du repository
2. Branche feature (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commits (`git commit -am 'Ajout nouvelle fonctionnalit√©'`)
4. Push (`git push origin feature/nouvelle-fonctionnalite`)
5. Pull Request

## Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

## Support

- **Documentation** : [Wiki du projet](wiki-url)
- **Issues** : [GitHub Issues](issues-url)
- **Contact** : equipe-ml@lakehouse-accidents.com