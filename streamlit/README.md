# üìä Dashboard Streamlit - Lakehouse US-Accidents

## Vue d'ensemble

Cette application Streamlit fournit une interface de visualisation interactive pour explorer les r√©sultats du pipeline lakehouse US-Accidents. Elle se connecte directement √† la base de donn√©es MySQL (couche Gold) pour afficher les KPIs, analyses et r√©sultats des mod√®les ML.

## Fonctionnalit√©s

### üè† Page d'Accueil
- Vue d'ensemble des m√©triques g√©n√©rales
- Architecture Medallion visualis√©e
- Statut du pipeline ETL

### üìä KPIs de S√©curit√©
- Top 10 √©tats les plus dangereux
- Taux d'accidents par 100k habitants
- Index de dangerosit√© par zone
- Distribution des hotspots

### ‚è∞ Analyse Temporelle
- √âvolution des accidents par p√©riode
- Analyse saisonni√®re
- Tendances par √©tat
- Facteurs temporels

### üó∫Ô∏è Hotspots G√©ographiques
- Carte interactive des zones dangereuses
- Top hotspots par √©tat
- Analyse g√©ospatiale
- Corr√©lations g√©ographiques

### ü§ñ Performance ML
- M√©triques des mod√®les (Accuracy, F1-score, etc.)
- Comparaison entre mod√®les
- Importance des features
- √âvolution des performances

### üìà Donn√©es Brutes
- Exploration interactive des donn√©es
- Filtres dynamiques
- Statistiques descriptives
- Export des donn√©es

## Installation

```bash
# Installation des d√©pendances
pip install -r requirements.txt

# D√©marrage de l'application
streamlit run app.py
```

## Configuration

L'application utilise la configuration MySQL d√©finie dans le fichier `.env` du projet principal :

```env
DB_HOST=localhost
DB_PORT=3306
DB_USER=tatane
DB_PASSWORD=tatane
DB_NAME=accidents_db
```

## Pr√©requis

1. **Pipeline ETL ex√©cut√©** : Les applications DATAMART et MLTRAINING doivent avoir √©t√© ex√©cut√©es pour peupler la base MySQL
2. **Base MySQL accessible** : La base de donn√©es doit √™tre accessible avec les tables suivantes :
   - `accidents_summary`
   - `kpis_security`
   - `kpis_temporal`
   - `hotspots`
   - `ml_model_performance`

## Utilisation

1. **D√©marrer l'infrastructure** :
   ```bash
   cd docker
   ./scripts/start-cluster.sh
   ```

2. **Ex√©cuter le pipeline ETL** :
   ```bash
   ./run.bat  # Windows
   ./run.sh   # Linux/Mac
   ```

3. **Lancer Streamlit** :
   ```bash
   cd streamlit
   streamlit run app.py
   ```

4. **Acc√©der au dashboard** : http://localhost:8501

## Architecture

```
streamlit/
‚îú‚îÄ‚îÄ app.py              # Application principale
‚îú‚îÄ‚îÄ requirements.txt    # D√©pendances Python
‚îî‚îÄ‚îÄ README.md          # Documentation
```

## Fonctionnalit√©s Techniques

- **Connexion MySQL** : Utilise mysql-connector-python
- **Visualisations** : Plotly Express et Graph Objects
- **Interface** : Streamlit avec layout responsive
- **Configuration** : Int√©gration avec ConfigManager du projet
- **Gestion d'erreurs** : Affichage des erreurs de connexion
- **Performance** : Requ√™tes optimis√©es avec LIMIT

## Captures d'√âcran

L'application g√©n√®re automatiquement :
- Graphiques interactifs Plotly
- Cartes g√©ographiques avec hotspots
- Tableaux de donn√©es filtrables
- M√©triques en temps r√©el
- Comparaisons de mod√®les ML

## D√©pannage

### Erreur de connexion MySQL
```
Erreur de connexion √† MySQL: [Errno] Can't connect to MySQL server
```
**Solution** : V√©rifier que MySQL est d√©marr√© et accessible avec les param√®tres du .env

### Aucune donn√©e disponible
```
Aucune donn√©e disponible. Ex√©cutez d'abord le pipeline complet.
```
**Solution** : Ex√©cuter le pipeline ETL avec `./run.bat` ou `./run.sh`

### Erreur d'import
```
ModuleNotFoundError: No module named 'src'
```
**Solution** : Lancer Streamlit depuis le r√©pertoire racine du projet

## Int√©gration

Cette application Streamlit s'int√®gre parfaitement avec :
- **Pipeline ETL** : Consomme les donn√©es g√©n√©r√©es
- **API FastAPI** : Peut utiliser les m√™mes endpoints
- **Infrastructure Docker** : Utilise la m√™me base MySQL
- **Configuration** : Partage le m√™me ConfigManager